{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b27b7a-ac88-4575-b1f5-d544dca62225",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa31c8-837b-4deb-b640-7316f572bc34",
   "metadata": {},
   "source": [
    "## Date & Zone info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e8f2bc-b46b-4e3b-9b7d-6257cc6e14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date of the previous of the day ahead prediction day (i.e. starting_date = '04/01/2024' or comment it out for auto getting today's date)\n",
    "# starting_date = '03/02/2024'\n",
    "\n",
    "# Define how many day(s) forward to predict (i.e. days_ahead = 1 means one day (24hours) ahead forecast)\n",
    "days_ahead = 1\n",
    "\n",
    "# Define the list with the bidding zone(s) for which to create predictions (i.e. zones = ['DE','FR','HU'])\n",
    "zones = ['DE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f525f-2416-42ca-9596-2344e8c43098",
   "metadata": {},
   "source": [
    "## Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a47216-bb9e-41d9-bf9b-e11c7c4286ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state whether to include the Naive model as forecasting model\n",
    "Naive_model = False\n",
    "# state whether to run and include the Time series models\n",
    "Time_series = True\n",
    "# Define start date for Timeseries\n",
    "startDate_TS = '2022-06-09'\n",
    "# define the number of days to look back from today for the evaluation step (Best_Hourly model)\n",
    "daysBack = 20\n",
    "\n",
    "# Define the training version of the models\n",
    "Training_version = 'v1'\n",
    "# Define the tables and their columns in MySQL that match those in the model training script\n",
    "Countries_dict = {\n",
    "  \t'v1':{\n",
    "  \t  \t'DE' : {\n",
    "\t\t\t'Fundamentals_forecast': ['Load_DE', 'Wind_DE', 'Solar_DE','Hydro_DE','Nuc_DE'],\n",
    "\t\t\t'GasSpot': ['THE'],\n",
    "\t\t\t'EUA': ['EUA_DecLastPrice'],\n",
    "\t\t\t'Prices': ['DE_LU'] },\n",
    "}}\n",
    "# Define tables with daily granularity in order to convert them to hourly granularity\n",
    "daily_granularity = ['GasSpot', 'EUA','GasFutures']\n",
    "# Define data Table from which the single prediction column is predicted\n",
    "TablePred = 'Prices'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87415cbb-f237-4444-b1f8-0cfb77449b86",
   "metadata": {},
   "source": [
    "## Script info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cf9f99-8ead-40f8-9597-5d5e75fbeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state whether to create the evaluation plots\n",
    "create_plots = False\n",
    "# state whether to notify via Teams over the forecasts completion for the current and for all zones\n",
    "Teams_notification = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d0491-4d7f-46bc-ae74-fc6d51b0254f",
   "metadata": {},
   "source": [
    "# Libraries, connections & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6763d78-6c67-469d-98f0-a8abe4490587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Please input your main path folder in the script: folder.py . If already done then skip this step.\n"
     ]
    }
   ],
   "source": [
    "#------- Libraries\n",
    "# Time\n",
    "from datetime import datetime, date, timedelta\n",
    "import holidays\n",
    "# Data\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "from numpy import arange, mean, std\n",
    "from functools import reduce\n",
    "import collections\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "# graphics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandasgui\n",
    "import pygwalker as pyg\n",
    "# ML\n",
    "from tensorflow import keras\n",
    "# Timeseries\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pmdarima as pm\n",
    "from scalecast.Forecaster import Forecaster\n",
    "from tbats import TBATS\n",
    "from ThymeBoost import ThymeBoost as tb\n",
    "# System\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import PySimpleGUI as sg\n",
    "import warnings\n",
    "# Turning off the Deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# helper script for the evaluation of Best_Hourly model\n",
    "import Models_Evaluation\n",
    "\n",
    "# helper script containing several functions to communicate with MySQL\n",
    "import MySQL_functions\n",
    "# connection info to connect to MySQL server\n",
    "MySQL_info = { 'user':'python',\n",
    "\t\t\t\t'passw':'sentrade_admin',\n",
    "\t\t\t\t'host':'172.24.70.213',\n",
    "\t\t\t\t'port' : 3306,\n",
    "\t\t\t\t'database_name':'MORE_Trading' }\n",
    "\n",
    "# helper script to define users folder pathes\n",
    "import folders\n",
    "Path_dict = folders.folder()\n",
    "ModelPathFolder = Path_dict['Models']\n",
    "\n",
    "#------- Functions\n",
    "# define function to make predictions\n",
    "def ModelsForecast(model_name, X_forecasts):\n",
    "\t# model names list\n",
    "\tRNN_model_names = ['LSTM','BILSTM','GRU','LSTM1','LSTM2','LSTM3','LSTM4','GRU1','GRU2','GRU3','BILSTM1','BILSTM2','BILSTM3']\t\n",
    "\t# load model ( different loading based if it is a NN or not)\n",
    "\tif model_name in RNN_model_names:\n",
    "\t\t# Model file location\n",
    "\t\tFilePath_JSON = ModelPathFolder + project + model_name + '.JSON'\n",
    "\t\tFilePath_h5 = ModelPathFolder + project + model_name + '.h5'\n",
    "\t\t# load json and create model\n",
    "\t\tjson_file = open(FilePath_JSON, 'r')\n",
    "\t\tloaded_model_json = json_file.read()\n",
    "\t\tjson_file.close()\n",
    "\t\tmodel = model_from_json(loaded_model_json)\n",
    "\t\t# load weights into new model\n",
    "\t\tmodel.load_weights(FilePath_h5)\n",
    "\telse:\t\t\n",
    "\t\t# file location on disk\n",
    "\t\tModelFilePath = ModelPathFolder + project + model_name + '.sav'\n",
    "\t\t# load the model\n",
    "\t\tmodel = pickle.load(open(ModelFilePath, 'rb'))\n",
    "\t\t\n",
    "\t# load scaler for X Forecast features\n",
    "\tScalerFilePath = ModelPathFolder + project + 'X_scaler.sav'\n",
    "\tscaler = pickle.load(open(ScalerFilePath , 'rb'))\n",
    "\t# extraxt all the column names with order in which they were scaled and reorder the pandas dataframe\n",
    "\tX_forecasts.columns = scaler.get_feature_names_out()\n",
    "\t# scale Forecast features\n",
    "\tX_forecasts_scaled = scaler.transform(X_forecasts)\n",
    "\t\n",
    "\t# make 3D matrix for RNNs\n",
    "\tif model_name in RNN_model_names:\n",
    "\t\ttime_steps=1\n",
    "\t\tXs = []\n",
    "\t\tfor i in range(len(X_forecasts_scaled) - time_steps):\n",
    "\t\t\tv = X_forecasts_scaled[i:i + time_steps, :]\n",
    "\t\t\tXs.append(v)\n",
    "\t\tX_forecasts_scaled_final = np.array(Xs)\n",
    "\telse:\n",
    "\t\tX_forecasts_scaled_final = X_forecasts_scaled\n",
    "\n",
    "\t# Make prediction\n",
    "\tY_forecasts_model = model.predict(X_forecasts_scaled_final)\n",
    "\t\t\n",
    "\t# ------ Scale Y and other transformation on the predictions ------ \n",
    "\tif model_name in RNN_model_names:\n",
    "\t\t# load the Y scaler from disk\n",
    "\t\tScalerFilePath = ModelPathFolder + project + 'Y_scaler.sav'\n",
    "\t\tscaler_Y = pickle.load(open(ScalerFilePath, 'rb'))\n",
    "\t\tY_forecasts = scaler_Y.inverse_transform(Y_forecasts_model.reshape(-1, 1))\n",
    "\t\t# as the last prediction value is non defined mask it with the latest one\n",
    "\t\tY_forecasts = np.insert(Y_forecasts,len(Y_forecasts),Y_forecasts[-1])\n",
    "\telif model_name == 'MLP':\n",
    "\t\tY_forecasts =  pd.Series( Y_forecasts_model.flatten() )\n",
    "\telse:\n",
    "\t\tY_forecasts =  Y_forecasts_model\n",
    "\t\t\n",
    "\t# return predictions\n",
    "\treturn Y_forecasts.astype(float).round(2)\n",
    "\n",
    "\n",
    "# function to post the notification to Teams\n",
    "def send_teams(webhook_url:str, content:str, title:str, color:str=\"#bfbf9f\"):\n",
    "\tresponse_TEAMS = requests.post(\n",
    "\t\turl=webhook_url,\n",
    "\t\theaders={\"Content-Type\": \"application/json\"},\n",
    "\t\tjson={\n",
    "\t\t\t\"themeColor\": color,\n",
    "\t\t\t\"summary\": title,\n",
    "\t\t\t\"sections\": [{\n",
    "\t\t\t\t\"activityTitle\": title,\n",
    "\t\t\t\t\"activitySubtitle\": content\n",
    "\t\t\t}],\n",
    "\t\t},\n",
    "\t)\n",
    "\tif response_TEAMS.status_code == 200:\n",
    "\t\tposted = 'Posted to Teams'\n",
    "\telse:\n",
    "\t\tposted = 'Error - not posted to Teams'\n",
    "\treturn posted\n",
    "\n",
    "#------- \n",
    "# initiate dictionary to store suggested models and predictions for all zones and days ahead\n",
    "SuggPredictions = collections.defaultdict(lambda : collections.defaultdict(dict))\n",
    "\n",
    "# ML Model names list to run\n",
    "model_names = ['LinearRegression','Lasso','Ridge','kNN','XGB','RandomForest','GAM','SVM','GBM','AdaBoost','CatBoost','EXT','MLP','LSTM','BILSTM','GRU','LSTM1','LSTM2','LSTM3','LSTM4','GRU1','GRU2','GRU3','BILSTM1','BILSTM2','BILSTM3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c59a5-0a18-4e84-a006-44b809d01cda",
   "metadata": {},
   "source": [
    "# Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a9207-ca4a-469b-87d3-19b5e8a007ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project name: DE_Prices_v1_\n",
      "\n",
      "Prediction starting timestamp: 2024-02-04 00:00:00  - ending timestamp: 2024-02-04 23:00:00\n",
      "Query created: SELECT Datetime,Load_DE, Wind_DE, Solar_DE, Hydro_DE, Nuc_DE FROM Fundamentals_forecast WHERE DATE(Datetime) BETWEEN \"2024-02-04 00:00:00\" AND \"2024-02-04 23:00:00\";\n",
      "Query created: SELECT DeliveryStart, SettlementPrice as THE FROM MORE_Trading.GasSpot where Market=\"THE\" AND DeliveryStart <= \"2024-02-04 00:00:00\" ORDER BY DeliveryStart DESC LIMIT 1;\n",
      "Query created: SELECT Datetime, EUA_DecLastPrice FROM MORE_Trading.EUA WHERE EUA_DecLastPrice IS NOT NULL AND Datetime <= \"2024-02-04 00:00:00\" ORDER BY Datetime DESC LIMIT 1;\n",
      "Query created: SELECT Datetime,DE_LU FROM Prices WHERE DATE(Datetime) BETWEEN \"2022-06-09\" AND \"2024-02-03 00:00:00\";\n",
      "\n",
      "Missing values:\n",
      " Datetime            0\n",
      "Load_DE             0\n",
      "Wind_DE             0\n",
      "Solar_DE            0\n",
      "Hydro_DE            0\n",
      "Nuc_DE              0\n",
      "THE                 0\n",
      "EUA_DecLastPrice    0\n",
      "dtype: int64 \n",
      "Table size: (24, 8)\n",
      "\n",
      "All NaN values were imputated\n",
      "                          Load_DE       Wind_DE     Solar_DE     Hydro_DE  \\\n",
      "Datetime                                                                    \n",
      "2024-02-04 00:00:00  48787.387432  37744.526667     0.000000  2083.626465   \n",
      "2024-02-04 01:00:00  46283.717879  39524.032561     0.000000  2082.782959   \n",
      "2024-02-04 02:00:00  44806.072786  41032.588357     0.000000  2074.708984   \n",
      "2024-02-04 03:00:00  44348.090458  42281.303700     0.000000  2070.290527   \n",
      "2024-02-04 04:00:00  43512.815110  42955.513392     0.000000  2062.819092   \n",
      "2024-02-04 05:00:00  43331.276236  44003.946337     0.000000  2055.146973   \n",
      "2024-02-04 06:00:00  43192.556056  45186.149417     0.000000  2044.462036   \n",
      "2024-02-04 07:00:00  46896.501648  45439.879345    12.075609  2037.352295   \n",
      "2024-02-04 08:00:00  50558.694538  46131.550156   794.681641  2042.172485   \n",
      "2024-02-04 09:00:00  55150.021070  46937.430734  2777.120605  2058.681885   \n",
      "2024-02-04 10:00:00  57587.274167  47393.831647  4586.392578  2074.427979   \n",
      "2024-02-04 11:00:00  59982.943318  48053.611590  6429.804688  2074.869629   \n",
      "2024-02-04 12:00:00  59799.019169  48599.426746  7242.195801  2074.468018   \n",
      "2024-02-04 13:00:00  58135.642105  49029.355447  6544.577637  2074.146729   \n",
      "2024-02-04 14:00:00  56913.880181  49113.825136  5164.337891  2085.193115   \n",
      "2024-02-04 15:00:00  55208.148582  48933.313313  3066.400146  2078.685791   \n",
      "2024-02-04 16:00:00  55851.018956  47935.311520  1048.032349  2067.398438   \n",
      "2024-02-04 17:00:00  58877.595829  47065.909995    38.340008  2052.214600   \n",
      "2024-02-04 18:00:00  61220.923548  48394.490257     0.000000  2040.686279   \n",
      "2024-02-04 19:00:00  61077.499090  49688.461656     0.000000  2040.284546   \n",
      "2024-02-04 20:00:00  59278.575560  49328.550849     0.000000  2036.428345   \n",
      "2024-02-04 21:00:00  56864.231433  47285.116216     0.000000  2036.548828   \n",
      "2024-02-04 22:00:00  55592.590551  47073.192023     0.000000  2045.626953   \n",
      "2024-02-04 23:00:00  52620.068552  44971.527291     0.000000  2054.544434   \n",
      "\n",
      "                     Nuc_DE    THE  EUA_DecLastPrice  \n",
      "Datetime                                              \n",
      "2024-02-04 00:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 01:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 02:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 03:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 04:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 05:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 06:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 07:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 08:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 09:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 10:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 11:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 12:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 13:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 14:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 15:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 16:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 17:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 18:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 19:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 20:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 21:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 22:00:00     0.0  28.93         62.299999  \n",
      "2024-02-04 23:00:00     0.0  28.93         62.299999  \n",
      "Model running: LinearRegression\n",
      "Model running: Lasso\n",
      "Model running: Ridge\n",
      "Model running: kNN\n",
      "Model running: XGB\n",
      "Model running: RandomForest\n",
      "Model running: GAM\n",
      "Model running: SVM\n",
      "Model running: GBM\n",
      "Model running: AdaBoost\n",
      "Model running: CatBoost\n",
      "Model running: EXT\n",
      "Model running: MLP\n",
      "Model running: LSTM\n",
      "WARNING:tensorflow:From C:\\Users\\Akitsatoglou\\.conda\\envs\\conda_env_1\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 0s 456ms/step\n",
      "Model running: BILSTM\n",
      "1/1 [==============================] - 1s 762ms/step\n",
      "Model running: GRU\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "Model running: LSTM1\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Model running: LSTM2\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B0663B920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Model running: LSTM3\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B07535580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Model running: LSTM4\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Model running: GRU1\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Model running: GRU2\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Model running: GRU3\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Model running: BILSTM1\n",
      "1/1 [==============================] - 1s 737ms/step\n",
      "Model running: BILSTM2\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Model running: BILSTM3\n",
      "1/1 [==============================] - 1s 809ms/step\n",
      "********** Round 1 **********\n",
      "Using Split: None\n",
      "Fitting initial trend globally with trend model:\n",
      "median()\n",
      "seasonal model:\n",
      "None\n",
      "cost: 20000.991552320935\n",
      "********** Round 2 **********\n",
      "Using Split: None\n",
      "Fitting global with trend model:\n",
      "linear((1, None))\n",
      "seasonal model:\n",
      "None\n",
      "cost: 11102.112130110767\n",
      "********** Round 3 **********\n",
      "Using Split: None\n",
      "Fitting global with trend model:\n",
      "arima(auto)\n",
      "seasonal model:\n",
      "None\n",
      "cost: 403.032462915394\n",
      "==============================\n",
      "Boosting Terminated \n",
      "Using round 3\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Akitsatoglou\\.conda\\envs\\conda_env_1\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "362/362 [==============================] - 12s 22ms/step - loss: 0.0516 - val_loss: 0.0205\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 7s 19ms/step - loss: 0.0373 - val_loss: 0.0196\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 7s 19ms/step - loss: 0.0364 - val_loss: 0.0317\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 6s 18ms/step - loss: 0.0356 - val_loss: 0.0203\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 7s 19ms/step - loss: 0.0346 - val_loss: 0.0235\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 7s 19ms/step - loss: 0.0332 - val_loss: 0.0187\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 6s 18ms/step - loss: 0.0310 - val_loss: 0.0212\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 6s 18ms/step - loss: 0.0298 - val_loss: 0.0197\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 6s 18ms/step - loss: 0.0287 - val_loss: 0.0206\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 7s 20ms/step - loss: 0.0284 - val_loss: 0.0174\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 8s 21ms/step - loss: 0.0281 - val_loss: 0.0177\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 9s 24ms/step - loss: 0.0281 - val_loss: 0.0183\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 8s 23ms/step - loss: 0.0276 - val_loss: 0.0177\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 8s 23ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 7s 21ms/step - loss: 0.0274 - val_loss: 0.0172\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 8s 23ms/step - loss: 0.0273 - val_loss: 0.0175\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 8s 23ms/step - loss: 0.0268 - val_loss: 0.0175\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 9s 25ms/step - loss: 0.0270 - val_loss: 0.0179\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 8s 21ms/step - loss: 0.0269 - val_loss: 0.0170\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 8s 22ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 15s 30ms/step - loss: 0.0510 - val_loss: 0.0237\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 13s 35ms/step - loss: 0.0376 - val_loss: 0.0231\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - ETA: 0s - loss: 0.0369"
     ]
    }
   ],
   "source": [
    "#------- Zones loop\n",
    "for zone in zones:\n",
    "\n",
    "\t# get country's holidays to decide whether to include naive model\n",
    "\tholidaysDates = holidays.country_holidays(zone)\n",
    "\n",
    "\t# define evaluation folder\n",
    "\tEvaluationPathFolder = Path_dict['Evaluation']+zone+'\\\\'+TablePred+'\\\\'+Training_version+'\\\\'\n",
    "\n",
    "\t# define project name\n",
    "\tproject = zone + '_' + TablePred + '_' + Training_version + '_'\n",
    "\tprint('Current project name:', project)\n",
    "\n",
    "\t# define Price name column\n",
    "\tColumPred = Countries_dict[Training_version][zone]['Prices'][0]\n",
    "\n",
    "\t#------- Dates ahead loop\n",
    "\tfor day_loop in range(0, days_ahead):\n",
    "\n",
    "\t#------- Dates\n",
    "\t\t# Define start and end date to retrieve data from MySQL database\n",
    "\t\ttry:\n",
    "\t\t\tstart_time = pd.to_datetime(starting_date, format='%d/%m/%Y') + timedelta(days=day_loop)\n",
    "\t\texcept NameError as ne:\n",
    "\t\t\tprint('Using current datetime..')\n",
    "\t\t\tstart_time = datetime.now() + timedelta(days=day_loop)\n",
    "\n",
    "\t\t# define today's date\n",
    "\t\tToday = pd.to_datetime(start_time.strftime('%Y-%m-%d'), format='%Y-%m-%d')\n",
    "\n",
    "\t   \t\t\n",
    "\t\t# define day ahead date start timestamp\n",
    "\t\tstart = (Today + timedelta(days=1) ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\t\t# define day ahead date end\n",
    "\t\tend = (Today + timedelta(days=1) + timedelta(hours=23)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\t\tprint('\\nPrediction starting timestamp:',start,' - ending timestamp:',end)\n",
    "\n",
    "\t\t# Initiate data frame to save forecasts\n",
    "\t\tForecasts = pd.DataFrame(pd.date_range(start, periods=24, freq='H'), columns=['Datetime'])\n",
    "\t\tForecasts['project'] = project\n",
    "\t\t\n",
    "\t\t# define table name for forecasted data\n",
    "\t\tTableForecasts = TablePred + '_forecast'\n",
    "\n",
    "\n",
    "\t#------- Import data\n",
    "\t\t# concatenate column and table names\n",
    "\t\tTables = []\n",
    "\t\tColumns = []\n",
    "\t\tfor table, columns in Countries_dict[Training_version][zone].items():\n",
    "\t\t\tColumns += columns\n",
    "\t\t\tTables.append(table)\n",
    "\t\t\n",
    "\t\t# initiate list to store dataframe created on the loop\n",
    "\t\tlist_of_dfs = []\n",
    "\t\t\n",
    "\t\t# loop through countries dictionary and retrieve data from MySQL\n",
    "\t\tfor table, columns in Countries_dict[Training_version][zone].items():\n",
    "\t\t\t# Table 'GasSpot' has a peculiar structure and needs different querry format\n",
    "\t\t\tif table == 'GasSpot':\n",
    "\t\t\t\tquery = f'SELECT DeliveryStart, SettlementPrice as {columns[0]} FROM MORE_Trading.GasSpot where Market=\"{columns[0]}\" AND DeliveryStart <= \"{start}\" ORDER BY DeliveryStart DESC LIMIT 1;'\n",
    "\t\t\t\tDF = MySQL_functions.ExecuteQuery(server_credentials = MySQL_info, query=query)\n",
    "\t\t\t\tDF.rename(columns={'DeliveryStart':'Datetime'}, inplace=True, errors='ignore')\n",
    "\t\t\telif table == \"EUA\":\n",
    "\t\t\t\tquery = f'SELECT Datetime, EUA_DecLastPrice FROM MORE_Trading.EUA WHERE EUA_DecLastPrice IS NOT NULL AND Datetime <= \"{start}\" ORDER BY Datetime DESC LIMIT 1;'\n",
    "\t\t\t\tDF = MySQL_functions.ExecuteQuery(server_credentials = MySQL_info, query=query)\n",
    "\t\t\t\tDF.rename(columns={'DeliveryStart':'Datetime'}, inplace=True, errors='ignore')\n",
    "\t\t\telif table == 'Prices':\n",
    "\t\t\t\tPrices = MySQL_functions.SelectData(server_credentials = MySQL_info, table_name=TablePred, columns=ColumPred, start=startDate_TS, end=Today.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\t\t\t\t# set all data to float\n",
    "\t\t\t\tPrices[ColumPred] = Prices[ColumPred].apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "\t\t\t\t# sort values by datetime\n",
    "\t\t\t\tPrices[\"Datetime\"] = pd.to_datetime(Prices[\"Datetime\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\t\t\t\tPrices.sort_values(by=\"Datetime\", inplace=True)\n",
    "\t\t\t\t# fill na values (cases of time change)\n",
    "\t\t\t\tPrices = Prices.fillna(method='ffill')\n",
    "\t\t\telse:\n",
    "\t\t\t\tDF = MySQL_functions.SelectData(server_credentials = MySQL_info, table_name=table, columns=columns, start=start,end=end)\n",
    "\t\t\t\n",
    "\t\t\t# print(table, columns,'\\n',DF)\n",
    "\t\t\t# check and then convert daily to hourly timestamp\n",
    "\t\t\tif table in daily_granularity:\n",
    "\t\t\t\tfor column in columns:\n",
    "\t\t\t\t\t# create dataframe with day ahead datetime\n",
    "\t\t\t\t\tdf = pd.DataFrame(index=pd.date_range(start, end, freq=\"H\"))\n",
    "\t\t\t\t\tdf.index.name = 'Datetime'\n",
    "\t\t\t\t\tdf[column] = DF[column][0]\n",
    "\t\t\t\t\t# add dataframe to the respective list\n",
    "\t\t\t\t\tlist_of_dfs.append(df)\n",
    "\t\t\telif table == 'Prices':\n",
    "\t\t\t\tpass\n",
    "\t\t\telse:\n",
    "\t\t\t\t# set Datetime as datetime object\n",
    "\t\t\t\tDF['Datetime'] = pd.to_datetime(DF['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\t\t\t\t# add dataframe to the respective list\n",
    "\t\t\t\tlist_of_dfs.append(DF)\n",
    "\t\t\n",
    "\t\t# Merge dataframes from the list to a single dataframe\n",
    "\t\tData = reduce(lambda x, y: pd.merge(x,y, on='Datetime'), list_of_dfs)\n",
    "\t\t\t\t\n",
    "\t\t# Show all missing values\n",
    "\t\tprint('\\nMissing values:\\n', Data.isnull().sum(),\n",
    "\t\t\t'\\nTable size:', Data.shape)\n",
    "\t\t\n",
    "\t\t# Replace NULL values with the value from the ffill: previous row bfill: next row\n",
    "\t\tdata = Data.fillna(method='ffill').fillna(method='bfill')\n",
    "\t\tprint('\\nAll NaN values were imputated')\n",
    "\t\t# set Datetime as index\n",
    "\t\tdata.set_index('Datetime', inplace=True)\n",
    "\t\t# set all data to float\n",
    "\t\tdata = data.apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "\t\t# ------- \n",
    "\t\t# show data statisticss\n",
    "\t\t# print(data.describe())\n",
    "\t\t# append data to excel to keep historical forecasts\n",
    "\t\tdata.to_csv(EvaluationPathFolder+'Attributes forecasts.csv', mode='a',index=True, header=False)\n",
    "\t\t# show data\n",
    "\t\tprint(data)\n",
    "\n",
    "\t#------- ML models forecasts\t\n",
    "\t\t# Run model's list\n",
    "\t\tfor model in model_names:\n",
    "\t\t\tprint('Model running:', model)\n",
    "\t\t\tForecasts[model] = ModelsForecast(model, data)\n",
    "\n",
    "\n",
    "\t#------- Naive and Timeseries models checks for inclusion\n",
    "\n",
    "\t\t# 1.Check dates for holidays and weekends in order to decide whether Naive prices is suitable\n",
    "\t\t# check for holiday for Today\n",
    "\t\tif (Today.strftime('%A') in [ 'Saturday','Sunday']) | (Today.strftime('%Y-%m-%d') in holidaysDates):\n",
    "\t\t\tToday_holiday = True\n",
    "\t\telse:\n",
    "\t\t\tToday_holiday = False\n",
    "\t\t# check for holiday for the DayAhead\n",
    "\t\tif ((Today + timedelta(days=1)).strftime('%A') in [ 'Saturday','Sunday']) | ((Today + timedelta(days=1)).strftime('%Y-%m-%d') in holidaysDates):\n",
    "\t\t\tDayAhead_holiday = True\n",
    "\t\telse:\n",
    "\t\t\tDayAhead_holiday = False\n",
    "\t\t# if Today and DayAhead match exclude Naive model\n",
    "\t\tif Today_holiday != DayAhead_holiday:\n",
    "\t\t\tNaive_model = False\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\t\t# 2.Check if Prices are up to the latest day to decide for Naive and Timeseries models\n",
    "\t\tif Naive_model or Time_series:\n",
    "\t\t\tif list(Prices['Datetime'].iloc[-24:,] + timedelta(days=1)) != list(Forecasts['Datetime']):\n",
    "\t\t\t\tif days_ahead > 1 and day_loop != 0:\n",
    "\t\t\t\t\tprint('Script will continue to run without Naive and Timeseries models.')\n",
    "\t\t\t\t\tNaive_model = False\n",
    "\t\t\t\t\tTime_series = False\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsg.theme('DarkAmber')   # Add a touch of color\n",
    "\t\t\t\t\t# All the stuff inside your window.\n",
    "\t\t\t\t\tlayout = [[sg.Text('Hstorical prices timestamp are not up to date. If you want to continue without the Time series and Naive model press \"Continue without\" else \"Cancel\" and run respective script to fill the database and rerun from here and below.')], [sg.Button('Continue without'), sg.Button('Cancel')]]\n",
    "\t\t\t\t\t# Create the Window\n",
    "\t\t\t\t\twindow = sg.Window('Price forecasting alert', layout)\n",
    "\t\t\t\t\t# Event Loop to process \"events\" and get the \"values\" of the inputs\n",
    "\t\t\t\t\tevent, values = window.read()\n",
    "\t\t\t\t\tif event == sg.WIN_CLOSED or event == 'Cancel':\n",
    "\t\t\t\t\t\tprint('Script has stopped running.')\n",
    "\t\t\t\t\t\twindow.close()\n",
    "\t\t\t\t\t\traise SystemExit(0)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint('Script will continue to run without Naive and Timeseries models.')\n",
    "\t\t\t\t\t\tNaive_model = False\n",
    "\t\t\t\t\t\tTime_series = False\n",
    "\t\t\t\t\t\twindow.close()\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\n",
    "\t\t\t\t\n",
    "\t#------- Time series models forecasts ---\n",
    "\t\tif Time_series:\t\t\n",
    "\t\t\tmodel_name = 'SARIMA_TS'\t\n",
    "\t\t\t# create model\n",
    "\t\t\tSARIMAmodel = SARIMAX(endog = Prices[ColumPred],order = (3,0,3), seasonal_order=(2,1,0,7),\n",
    "\t\t\t\t\t\t\t\tenforce_stationarity=False, enforce_invertibility=False)\n",
    "\t\t\t# fit model\n",
    "\t\t\tresults = SARIMAmodel.fit()\n",
    "\t\t\t# Generate predictions\n",
    "\t\t\tPredictions_LowerUpper = results.get_forecast(24).conf_int(alpha = 0.05) \n",
    "\t\t\t# store predictions in dataframe\n",
    "\t\t\tForecasts[model_name] = Predictions_LowerUpper.mean(axis=1).reset_index(drop=True)\n",
    "\t\t\n",
    "\t\t\tmodel_name = 'ETS_TS'\t\n",
    "\t\t\t# create and fit model\n",
    "\t\t\tets_model = ExponentialSmoothing(endog=Prices[ColumPred], trend='additive', seasonal='additive',seasonal_periods=12,damped=True)\n",
    "\t\t\t# fit model\n",
    "\t\t\tets_model = ets_model.fit(optimized=True, remove_bias=False)\t\n",
    "\t\t\t# Generate predictions  \n",
    "\t\t\tPredictions = ets_model.forecast(24)\t\n",
    "\t\t\t# Generate predictions\n",
    "\t\t\tForecasts[model_name] = Predictions.reset_index(drop=True)\n",
    "\n",
    "\t\t\tmodel_name = \"GBLA_TS\"\t\n",
    "\t\t\t# create and fit model\n",
    "\t\t\tboosted_model = tb.ThymeBoost(verbose=1)\n",
    "\t\t\t# fit model\n",
    "\t\t\toutput = boosted_model.fit(Prices[ColumPred], trend_estimator=['linear', 'arima'], arima_order='auto', global_cost='mse')\n",
    "\t\t\t# Generate predictions  \n",
    "\t\t\tForecasts[model_name] = boosted_model.predict(output, 24).reset_index(drop=True)['predictions']\n",
    "\n",
    "\t\t\tmodel_name = \"LSTM_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tf = Forecaster(y=Prices[ColumPred], current_dates=Prices['Datetime'])\n",
    "\t\t\t# observations to test the results\n",
    "\t\t\tf.set_test_length(24)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# create LSTM neural network\n",
    "\t\t\tf.set_estimator('lstm')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(call_me='lstm_best',\n",
    "\t\t\t\t\t\t\tlags=24,\n",
    "\t\t\t\t\t\t\tbatch_size=32,\n",
    "\t\t\t\t\t\t\tepochs=20,\n",
    "\t\t\t\t\t\t\tvalidation_split=.2,\n",
    "\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\t\toptimizer='Adam',\n",
    "\t\t\t\t\t\t\tlearning_rate=0.001,\n",
    "\t\t\t\t\t\t\tlstm_layer_sizes=(72,)*4,\n",
    "\t\t\t\t\t\t\tdropout=(0,)*4,\n",
    "\t\t\t\t\t\t\tplot_loss=False)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"Ridge_TS\"\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index )\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('ridge')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(alpha=0.11)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"Lasso_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('lasso')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(alpha=0.01)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"GBT_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('gbt')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(max_depth = 3, max_features = None)   \n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"kNN_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('knn')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(n_neighbors = 61)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"MLP_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('mlp')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(activation = 'relu', hidden_layer_sizes = (25,), solver= 'lbfgs')\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast  \n",
    "\n",
    "\t\t\tmodel_name = \"MLR_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('mlr')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast()\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"RF_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('rf')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(max_depth = 5, n_estimators = 100, max_features = 'sqrt', max_samples = 0.75)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"SVR_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('svr')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(kernel = 'linear', C = 3, epsilon = 0.01)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\n",
    "\t\t\tmodel_name = \"XBD_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('xgboost')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(n_estimators = 150, scale_pos_weight = 5, learning_rate = 0.1, gamma = 5, subsample = 0.8)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\n",
    "\t\t\tmodel_name = \"LXBD_TS\"\t\n",
    "\t\t\t# define data\n",
    "\t\t\tdf = Prices\n",
    "\t\t\tdf = df.set_index('Datetime').asfreq('h')\n",
    "\t\t\t# fit data to forecaster\n",
    "\t\t\tf = Forecaster(y=df[ColumPred], current_dates = df.index)\n",
    "\t\t\t# future points to forecast\n",
    "\t\t\tf.generate_future_dates(24)\n",
    "\t\t\t# add AR terms\n",
    "\t\t\tf.add_ar_terms(1)\n",
    "\t\t\t# add seasonal AR terms\n",
    "\t\t\tf.add_AR_terms((3,3))\n",
    "\t\t\t# # add seasonal regressors\n",
    "\t\t\tf.add_seasonal_regressors('day',raw=False,sincos=True)\n",
    "\t\t\t# add time regressor\n",
    "\t\t\tf.add_time_trend()\t\n",
    "\t\t\t# create model\n",
    "\t\t\tf.set_estimator('lightgbm')\n",
    "\t\t\t# make predictions\n",
    "\t\t\tf.manual_forecast(n_estimators = 150, boosting_type = 'goss', max_depth = 2, learning_rate = 0.1)\t\n",
    "\t\t\t# Generate predictions \n",
    "\t\t\tForecasts[model_name] = f.forecast\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\t\tif Naive_model:\n",
    "\t\t\tForecasts['Naive'] = Prices[ColumPred].iloc[-24:,].values\n",
    "\n",
    "\t\n",
    "\t#------- Custom models\n",
    "\t\ttry:\n",
    "\t\t\t#--- Best previous 3 days models\n",
    "\t\t\t# define dictionary to store the best models found from each past day. day=3 means yesterday\n",
    "\t\t\tBest_models = {}\n",
    "\t\t\t# define how many actual days back to search for best model\n",
    "\t\t\tdays = 3\n",
    "\t\t\t# define how many days back to search for days having data after which to stop\n",
    "\t\t\tsearch_ending = 60\n",
    "\t\t\t# set iterator for searching back\n",
    "\t\t\ti = 0\n",
    "\t\t\t\n",
    "\t\t\t# loop until number of days are found or search iterations is completed\n",
    "\t\t\twhile days > 0:\n",
    "\t\t\t\t# define timestamp os start and end of each past day\n",
    "\t\t\t\tday_from  = pd.to_datetime(Prices.iloc[-1,0].strftime('%Y-%m-%d'), format='%Y-%m-%d') - timedelta(days=i)\n",
    "\t\t\t\tday_from_str = (day_from).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\t\t\t\tday_until = (day_from + timedelta(hours=23))\n",
    "\t\t\t\tday_until_str = (day_until).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\t\t\t\t# retrieve Historical forecasts data from MySQL\n",
    "\t\t\t\tHistorical_forecasts = MySQL_functions.SelectData(server_credentials = MySQL_info, table_name=TableForecasts, columns='All', start=day_from_str,end=day_until_str)\n",
    "\t\t\t\t# Keep forecasts of the same project\n",
    "\t\t\t\tHistorical_forecasts = Historical_forecasts[Historical_forecasts['project'] == project]\n",
    "\t\t\t\t# if no data found iterate to the next day\n",
    "\t\t\t\tif Historical_forecasts.empty:\n",
    "\t\t\t\t\tprint('No data found in MySQL for:',day_from_str, day_until_str)\n",
    "\t\t\t\t\t# exit while loop if trying for more than 10 days back\n",
    "\t\t\t\t\tif i == search_ending:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# initiate dictionary to store metrics\n",
    "\t\t\t\t\tMetrics = []\n",
    "\t\t\t\t\t# exclude Best models and not other not necessary columns\n",
    "\t\t\t\t\tcolumns_toDrop = ['Datetime','project','Best_Average','Best_Hourly','Best_Daily','Best_811','Best_721','Best_631','Best_532']\n",
    "\t\t\t\t\tForecPrices = Historical_forecasts.drop(columns=columns_toDrop, errors='ignore')\n",
    "\t\t\t\t\t# Drop all columns with NaN values\n",
    "\t\t\t\t\tForecPrices = ForecPrices.dropna(axis=1)\n",
    "\t\t\t\t\t# define data range of Actual prices which to compare with on metrics\n",
    "\t\t\t\t\tActualPrices = Prices[(Prices['Datetime']>=np.datetime64(day_from)) & (Prices['Datetime']<=np.datetime64(day_until))]\n",
    "\t\t\t\t\t# define columns as lists\t\t\t\t\t\n",
    "\t\t\t\t\tlist1 = Forecasts.loc[:, ~Forecasts.columns.isin(['Datetime','project'])].columns\n",
    "\t\t\t\t\tlist2 = ForecPrices.columns\n",
    "\t\t\n",
    "\t\t\t\t\tif set(list1).issubset(list2):\n",
    "\t\t\t\t\t\t# loop through the columns\n",
    "\t\t\t\t\t\tfor column in list1:\n",
    "\t\t\t\t\t\t\tif ForecPrices[column].values.any() != None:\n",
    "\t\t\t\t\t\t\t\tmae = mean_absolute_error(ActualPrices[ColumPred].values, ForecPrices[column].values).astype(float).round()\n",
    "\t\t\t\t\t\t\t\trmse = mean_squared_error(ActualPrices[ColumPred].values, ForecPrices[column].values, squared=False).astype(float).round()\n",
    "\t\t\t\t\t\t\t\tmape = mean_absolute_percentage_error(ActualPrices[ColumPred].values, ForecPrices[column].values)\t\t  \n",
    "\t\t\t\t\t\t\t\t# store metrics to dictionary\n",
    "\t\t\t\t\t\t\t\tMetrics.append({'model':column, 'mae':mae, 'rmse': rmse, 'mape': round(mape,2)})\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t# sort metrics according to mae\n",
    "\t\t\t\t\t\tsorted_list = sorted(Metrics, key=lambda d: d['mae']) \n",
    "\t\t\t\t\t\t# add best model to relative dictionary\n",
    "\t\t\t\t\t\tfor r, rank_model in enumerate(sorted_list):\n",
    "\t\t\t\t\t\t\tprint('\\n For day',days,'the best model found is', rank_model,'\\n\\n')\n",
    "\t\t\t\t\t\t\t# check if the best column found is included in today's forecasts\n",
    "\t\t\t\t\t\t\tif rank_model['model'] in Forecasts.columns:\n",
    "\t\t\t\t\t\t\t\tBest_models[str(days)] = rank_model['model']\n",
    "\t\t\t\t\t\t\t\tdays -= 1\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t# increase day back search iterator\n",
    "\t\t\t\ti += 1\n",
    "\t\t\t\n",
    "\t\t\t# Save models to dataframe\n",
    "\t\t\ttry:\n",
    "\t\t\t\tForecasts['Best_Daily'] = Forecasts[Best_models['3']]\n",
    "\t\t\t\tForecasts['Best_811'] = Forecasts[Best_models['3']]*0.8 + Forecasts[Best_models['2']]*0.1 + Forecasts[Best_models['1']]*0.1\n",
    "\t\t\t\tForecasts['Best_721'] = Forecasts[Best_models['3']]*0.7 + Forecasts[Best_models['2']]*0.2 + Forecasts[Best_models['1']]*0.1\n",
    "\t\t\t\tForecasts['Best_631'] = Forecasts[Best_models['3']]*0.6 + Forecasts[Best_models['2']]*0.3 + Forecasts[Best_models['1']]*0.1\n",
    "\t\t\t\tForecasts['Best_532'] = Forecasts[Best_models['3']]*0.5 + Forecasts[Best_models['2']]*0.3 + Forecasts[Best_models['1']]*0.2\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint('\\nException occurred in forming Best models!\\n', e)\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t#--- Best Hourly\n",
    "\t\t\t# function to make the evaluation\n",
    "\t\t\tEvaluation_df = Models_Evaluation.Evaluation_project(server_credentials=MySQL_info,zone=zone, TablePred=TablePred, ColumPred=ColumPred, Training_version=Training_version,  startdate=Today, daysBack=daysBack, create_plots=create_plots)\n",
    "\t\t\t\n",
    "\t\t\t# Load Best hourly table dictionary from disc\n",
    "\t\t\tRankingDictionaryPathFile = ModelPathFolder + 'Best_Hourly_Table.pkl'\n",
    "\t\t\twith open(RankingDictionaryPathFile, 'rb') as f:\n",
    "\t\t\t\tRankingTable = pickle.load(f)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tRankingTable = RankingTable[zone][TablePred][Training_version]\n",
    "\t\t\t\tBestModelResult = []\n",
    "\t\t\t\tfor i in range(0, 24, 1):\n",
    "\t\t\t\t\t# try successively the model based on the ranking\n",
    "\t\t\t\t\tfor c in range(1, len(RankingTable.columns) ):\n",
    "\t\t\t\t\t\tif RankingTable.iloc[i,c] in Forecasts.columns:\n",
    "\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\tBestModelColumnName = RankingTable.iloc[i,c]\n",
    "\t\t\t\t\t\t\t\tBestprediction = Forecasts.loc[i, BestModelColumnName]\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tBestModelResult.append(Bestprediction) \n",
    "\t\t\t\tModel_result = pd.DataFrame(BestModelResult, columns=['Best_Hourly'])\n",
    "\t\t\t\t# reset index\n",
    "\t\t\t\tModel_result.reset_index(drop=True, inplace=True)\n",
    "\t\t\t\n",
    "\t\t\t\t# save models to dataframe\n",
    "\t\t\t\tForecasts['Best_Hourly'] = Model_result\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint('\\nBest_Hourly model was not created due to exception:\\n',e)\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#--- Average of Best models\n",
    "\t\t\ttry:\n",
    "\t\t\t\tForecasts['Best_Average'] = Forecasts[['Best_Hourly','Best_Daily','Best_811','Best_721','Best_631','Best_532']].mean(axis=1)\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint('\\nBest_Average model was not created due to exception:\\n',e)\t   \n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#--- Suggested model\n",
    "\t\t\tfor j in range(len(Evaluation_df)):\n",
    "\t\t\t\tif Evaluation_df.iloc[j,0] in list(Forecasts.columns):\n",
    "\t\t\t\t\tsuggested_model = Evaluation_df.iloc[j,0]\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\t# form dataframe for the suggested model\n",
    "\t\t\tsuggested_df = Forecasts[['Datetime',suggested_model]]\n",
    "\t\t\tsuggested_df.rename(columns={suggested_model:'Prices /MWh'}, inplace=True)\n",
    "\t\t\t# add suggested model and predictions to dictionary\n",
    "\t\t\tSuggPredictions[zone][start]['model'] = suggested_model\n",
    "\t\t\tSuggPredictions[zone][start]['preds'] = suggested_df\n",
    "\t\t\t# print results\n",
    "\t\t\tprint('Suggested model as found the best one in the last',daysBack,'evaluation days is:',suggested_model)\n",
    "\t\t\tprint('Suggested predictions for', (Today + timedelta(days=1)).strftime('%d/%m'),'\\n',suggested_df)\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint('Exception found in custom models:\\n',e)\n",
    "\n",
    "\t\t# set Datetime as index\n",
    "\t\tForecasts = Forecasts.set_index('Datetime')\n",
    "\t\t# round numerical data after transforming to float64\n",
    "\t\tForecasts[Forecasts.select_dtypes(include=np.number).columns] = round(Forecasts[Forecasts.select_dtypes(include=np.number).columns].apply(pd.to_numeric, errors='coerce', axis=1), 2)\n",
    "\t\t# create a copy of datafram to upload\n",
    "\t\tUploadForecasts = Forecasts.copy()\n",
    "\t\t# exclude Naive model if included, from uploading to database as it can be found in Prices tables\n",
    "\t\ttry:\n",
    "\t\t\tUploadForecasts.drop(columns=['Naive'], axis=1, inplace=True)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\t\t\n",
    "\t#------- Upload forecasts to MySQL\n",
    "\t\tMySQL_functions.UpdateTable(MySQL_info, TableForecasts, UploadForecasts)\n",
    "\t\t# Create forecasts table if needed in MySQL\n",
    "\t\t#MySQL_functions.CreateTable(MySQL_info, TableForecasts, Forecasts, data_type = 'VARCHAR(50)')\n",
    "\n",
    "\n",
    "print('\\n\\n---------------------------- end of predictions ----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5e9fd-c92d-4c1b-9373-7d21b4b450ae",
   "metadata": {},
   "source": [
    "# Teams notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489c4cd-f5b3-4100-9dc8-5f151f46c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Consolidate suggested predictions\n",
    "# Define start and end date to retrieve data from MySQL database\n",
    "try:\n",
    "\tstart_time = pd.to_datetime(starting_date, format='%d/%m/%Y')\n",
    "except NameError as ne:\n",
    "\tstart_time = datetime.now()\n",
    "# define today's date\n",
    "Today = pd.to_datetime(start_time.strftime('%Y-%m-%d'), format='%Y-%m-%d')\n",
    "# define day ahead date start\n",
    "start = (Today + timedelta(days=1) ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Initiate data frame to save forecasts\n",
    "Teams_df = pd.DataFrame(pd.date_range(start, periods=24*days_ahead, freq='H'), columns=['Datetime'])\n",
    "# Initiate list to store suggested models\n",
    "suggested_models = []\n",
    "# loop to consolidate predictions\n",
    "for zone in zones:\n",
    "\tdates = list(SuggPredictions[zone].keys())\n",
    "\tdf = pd.DataFrame(columns=['Datetime', 'Prices /MWh'])\n",
    "\tfor date in dates:\n",
    "\t\tdf = pd.concat([df, SuggPredictions[zone][date]['preds']], axis=0)\n",
    " \n",
    "\tdf.rename(columns={'Prices /MWh':zone}, inplace=True)\n",
    "\tdf.reset_index(inplace=True, drop=True)\n",
    "\tdf['Datetime'] = pd.to_datetime(df[\"Datetime\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\tTeams_df = reduce(lambda x, y: pd.merge(x,y, on='Datetime'),[Teams_df,df])\n",
    "\tsuggested_models.append(SuggPredictions[zone][date]['model'])\n",
    "\n",
    "# reset index\n",
    "Teams_df.set_index('Datetime', inplace=True)\n",
    "# add averages at the end of the dataframe\n",
    "Teams_df.loc[('Average prices'), :] = Teams_df.mean(numeric_only=True).round(2)\n",
    "print(Teams_df)\n",
    "\n",
    "#------- Teams format\n",
    "# Teams URL\n",
    "URL_Teams = r'https://motoroil.webhook.office.com/webhookb2/75e42a1a-7489-4c96-ba48-271ddabd59aa@b1e32279-3c8b-4c06-9279-43fd8b1c329b/IncomingWebhook/76b43fcb38874355b59a1e452a510762/f45c382a-bdb5-420c-b723-08d7eadb0bdd'\n",
    "\n",
    "day_ref = 'day'\n",
    "# form layout text for teams for the suggested models \n",
    "if days_ahead>1:\n",
    "\tday_ref = 'days'\n",
    "if len(zones)>1:\n",
    "\tsuggested_models.append('respectively')\n",
    "Suggested_models = ', '.join(suggested_models)\n",
    "\n",
    "# define title content\n",
    "title = str(\"{}, {} {} ahead price predictions are ready!\".format( (Today + timedelta(days=1)).strftime('%d/%m'), days_ahead, day_ref ) )\n",
    "\n",
    "# define dataframe content\n",
    "pd.set_option('colheader_justify', 'center')\n",
    "Teams_df.reset_index(drop=False, inplace=True)\n",
    "preds_html = Teams_df.to_html(index=False, justify='justify-all').replace('<td>', '<td align=\"center\">')\n",
    "\n",
    "# define html content\n",
    "content = f\"\"\"\n",
    "<br>\n",
    "\n",
    "<ul>\n",
    "\t{preds_html}\n",
    "</ul>\n",
    "<br>\n",
    "<i> Suggested models: {Suggested_models} as evaluated for the last {daysBack} days </i>\n",
    "<br>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#------- Send to Teams\n",
    "if Teams_notification:\n",
    "\t# Send content\n",
    "\tsend_teams(URL_Teams, content, title)\n",
    "\tprint('\\n\\n> Predictions were posted to Teams!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24155ef3-c314-4934-a1e9-3b921731bb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
